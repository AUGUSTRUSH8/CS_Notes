# 模型选择和调优Grid Search
## 交叉验证(cross validation)  
交叉验证：将拿到的训练数据，分为训练和验证集。将数据分成四份，其中一份作为验证集。然后经过4次(组)的测试，每次都更换不同的验证集，即得到4组模型的结果，取平均数作为最终结果，又称为4折交叉验证。
## 分析  
我们之前知道数据分成训练集和测试集，但是为类让训练得到模型的结果更为准确，做以下处理  
- 训练集：训练集+验证集
- 测试集：测试集
- 得到不同的准确率，求平均值之后，平均值作为模型最终准确率

一组：**验证集** 训练集 训练集 训练集      
二组：训练集 **验证集** 训练集 训练集    
三组：训练集 训练集 **验证集** 训练集    
四组：训练集 训练集 训练集 **验证集**      

## 为什么需要交叉验证
- 交叉验证目的：为了让被评估的模型更加准确可信
- 如何选择或者调优参数

## 超参数搜索-网格搜索(Grid Search)
超参数 通常情况下，参数是需要手动指定的(如k-近邻算法中的k值)，这种叫超参数  

但是手动过程繁杂，所以需要对模型预设几种超参数组合。每组超参数都采用交叉验证来进行评估。最后选出最优参数组合建立模型。
```
k值   k=3   k=5   k=7
模型 模型1 模型2 模型3
```
## 模型选择与调优API
- **sklearn.model_selection.GridSearchCV(estimator,param_grid=None,cv=None)**
- 对估计器的指定参数进行详尽搜索
    - estimator:估计器对象
    - param_grid:估计器参数(dict)("n_neighbors":[1,3,5]) 准备好的k的取值，以字典的 形式传进来
    - cv:指定几折交叉验证 经过几次交叉验证 一般是10折
        - cv=3 训练集分成三分，其中一份测试，一共训练三次
- fit():输入训练数据
    - estimator.fit(x_train,y_train)
- predict():预测测试集结果
    - y_predict = estimator.predict(x_test)
    - print("y_predict:\n", y_predict)
- score():准确率
    - score = estimator.score(x_test,y_test)
    - print("准确率：\n",score)
- 结果分析:
    - 最佳参数: best_params_
    - 最佳结果: best_score_
    - 最佳估计器: best_estimator_
    - 交叉验证结果: cv_results_
    - p=1是曼哈顿距离，p=2是欧式距离
    

## 案例1鸢尾花案例增加K值调优
```python
# 导入数据集
from sklearn.datasets import load_iris
# 划分数据集
from sklearn.model_selection import train_test_split
# 数据标准化
from sklearn.preprocessing import StandardScaler
# 调用knn算法
from sklearn.neighbors import KNeighborsClassifier
# 调用gscv调优
from sklearn.model_selection import GridSearchCV

def knn_iris_gscv():
    '''
    用knn算法对鸢尾花进行分类, 添加网格搜索和交叉验证
    :return:
    '''
    # 获取数据
    iris = load_iris()
    # 划分数据
    x_train, x_test, y_train, y_test = train_test_split(iris.data,iris.target,random_state=6)
    # 特征工程：标准化
    transfer = StandardScaler()
    x_train = transfer.fit_transform(x_train)
    x_test = transfer.transform(x_test)
    # KNN算法预估器，因为要试，所以这里不需要加上k值
    estimator = KNeighborsClassifier()
    # 加入网格搜索和交叉验证
    ## 参数准备 k值 字典的格式
    param_dict = {"n_neighbors":[1,3,5,7,9,11]}
    estimator = GridSearchCV(estimator,param_grid=param_dict,cv=10)
    estimator.fit(x_train,y_train)
    # 模型评估
    y_predict = estimator.predict(x_test)
    print("y_predict:\n", y_predict)
    print("对比真实值和预测值：", y_predict == y_test )
    score = estimator.score(x_test,y_test)
    print("准确率：\n",score)
    # 最佳参数: best_params_
    print("最佳参数：",estimator.best_params_)
    # 最佳结果: best_score_
    # 此最佳结果是训练集中验证集当中的结果
    print("最佳结果",estimator.best_score_)
    # 最佳估计器: best_estimator_
    print("最佳估计器",estimator.best_estimator_)
    # 交叉验证结果: cv_results_
    print("交叉验证结果",estimator.cv_results_)
    return None

if __name__ == "__main__":
    knn_iris_gscv()
```    
```
output:
y_predict:
 [0 2 0 0 2 1 2 0 2 1 2 1 2 2 1 1 2 1 1 0 0 2 0 0 1 1 1 2 0 1 0 1 0 0 1 2 1
 2]
对比真实值和预测值： [ True  True  True  True  True  True  True  True  True  True  True  True
  True  True  True False  True  True  True  True  True  True  True  True
  True  True  True  True  True  True  True  True  True  True False  True
  True  True]
准确率：
 0.947368421053
最佳参数： {'n_neighbors': 5}
最佳结果 0.973214285714
```
## 案例2如何使用
```python
# 模型调优与选择
# 超参数搜索-网格搜索(Grid Search) GridSearchCV
# param_grid 为参数；参数候选项写成字典的格式
# cv 进行几次交叉验证

from sklearn.grid_search import GridSearchCV
tree_param_grid = { 'min_samples_split': list((3,6,9)),'n_estimators':list((10,50,100))}
grid = GridSearchCV(RandomForestRegressor(),param_grid=tree_param_grid, cv=5)
grid.fit(x_train, y_train)
grid.grid_scores_, grid.best_params_, grid.best_score_
```
```
output:
([mean: 0.78405, std: 0.00505, params: {'min_samples_split': 3, 'n_estimators': 10},
  mean: 0.80529, std: 0.00448, params: {'min_samples_split': 3, 'n_estimators': 50},
  mean: 0.80673, std: 0.00433, params: {'min_samples_split': 3, 'n_estimators': 100},
  mean: 0.79016, std: 0.00124, params: {'min_samples_split': 6, 'n_estimators': 10},
  mean: 0.80496, std: 0.00491, params: {'min_samples_split': 6, 'n_estimators': 50},
  mean: 0.80671, std: 0.00408, params: {'min_samples_split': 6, 'n_estimators': 100},
  mean: 0.78747, std: 0.00341, params: {'min_samples_split': 9, 'n_estimators': 10},
  mean: 0.80481, std: 0.00322, params: {'min_samples_split': 9, 'n_estimators': 50},
  mean: 0.80603, std: 0.00437, params: {'min_samples_split': 9, 'n_estimators': 100}],
 {'min_samples_split': 3, 'n_estimators': 100},
 0.8067250881273065)
```

- 带入min_samples_split': 3, 'n_estimators': 100测试
```python
rfr = RandomForestRegressor( min_samples_split=3,n_estimators = 100,random_state = 42)
rfr.fit(data_train, target_train)
rfr.score(data_test, target_test)
```
```
#结果一样
output:
0.80908290496531576 

```
## 流程分析
- 获取数据
- 数据处理
    - 特征值 x
    - 目标值 y
- 特征工程：标准化
- 算法预估流程
- 模型选择与调优
- 模型评估
