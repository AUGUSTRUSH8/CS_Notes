# 逻辑回归与二分类
- 逻辑回归(Logistic Regression)是机器学习中的一种分类模型，逻辑回归是一种分类算法。虽然名字里面带有回归，但是他与回归之间有一定的联系。由于算法的简单和高效，在实际中应用广泛

## 1逻辑回归应用场景
- 广告点击率
- 是否为垃圾邮件
- 是否患病
- 金融诈骗
- 虚假账号
- 以上的例子，发现其中的特点，那就是都是属于**两个类别之间的判断**，逻辑回归就是解决**二分类问题**的利器

## 2逻辑回归的原理
- 输入  
    - h(w)=w1x1+w2x2+w3x3...+b
    - 逻辑回归的输入就是一个线性回归的结果
    - 线性回归的输出，就是逻辑回归的输入
- 激活函数
    - sigmoid函数
    - 将回归结果输入到sigmoid函数当中
 
![逻辑回归激活函数](https://raw.githubusercontent.com/mayu1031/CS_Notes/master/doc/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0.png)  

![函数图像](https://raw.githubusercontent.com/mayu1031/CS_Notes/master/doc/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/%E5%87%BD%E6%95%B0%E5%9B%BE%E5%83%8F.png)

- 输出结果:[0,1]区间中的一个概率值，默认为0.5的阈值 (阈值可以设定，大于阈值，属于这个分类，小于阈值则不属于这个分类)
- 逻辑回归最终的分类是通过属于某个类别的概率值来判断是否属于某个类别，并且这个类别默认标记为1(正例)，另外的一个类别会标记为0(反例)，方便损失计算


## 3损失函数
- 将线性回归的输出映射到[0,1]区间中的一个数，1/(1 + e^(-(w1x1+w2x2+w3x3...+wnxn+b)))，设定一个阈值，大于阈值属于这个类，小于阈值则不属于这个类；如果得出一组权重和偏置，使得这个模型能够准确的进行分类和预测，就需要构建一个损失函数
- 使得损失函数取得最小值，得到此时的权重值和偏置

### 3.1对数似然损失
- 分开类别：

![分开类别](https://raw.githubusercontent.com/mayu1031/CS_Notes/master/doc/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/%E5%AF%B9%E6%95%B0%E4%BC%BC%E7%84%B6%E6%8D%9F%E5%A4%B1.png)  

![当y=1](https://raw.githubusercontent.com/mayu1031/CS_Notes/master/doc/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/%E5%AF%B9%E6%95%B0%E4%BC%BC%E7%84%B6%E6%8D%9F%E5%A4%B1y%3D1.png)  

- h(x)为将线性回归的输出映射到[0,1]区间中的一个数
- y=1 真实值属于这个类别即y=1，h(x)越接近1，预测的越准确，损失函数越低，接近为0

![当y=0](https://raw.githubusercontent.com/mayu1031/CS_Notes/master/doc/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/%E5%AF%B9%E6%95%B0%E4%BC%BC%E7%84%B6%E6%8D%9F%E5%A4%B1y%3D0.png)  

- h(x)为将线性回归的输出映射到[0,1]区间中的一个数   
- y=0 真实值不属于这个类别即为0，h(x)越接近0，同理预测结果越准确，则损失函数越低，接近为0

- 综合完整损失函数

![综合完整损失函数](https://raw.githubusercontent.com/mayu1031/CS_Notes/master/doc/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/%E7%BB%BC%E5%90%88%E5%AE%8C%E6%95%B4%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0.png)  

![损失函数例子](https://raw.githubusercontent.com/mayu1031/CS_Notes/master/doc/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%BE%8B%E5%AD%90.png)

- 我们已经知道log(p)，p值越大，结果越大

## 4优化损失
- 同样使用**梯度下降**优化算法，**调整权重参数**，去减少损失函数的值，更新逻辑回归前面对应算法的权重参数，**提高**原本属于1类别的概率，**降低**原本是0类别的概率

## 5逻辑回归API
- **sklearn.linear_model.LogisticRegression(solver='liblinear',penalty='L2',C=1.0)**
- 也在linear_model线性模型里面，我们对他进一步加工
    - solver: 优化求解方式(默认开源的liblinear库实现，内部使用了坐标轴下降法来迭代优化损失函数)
        - sag:根据数据集自动选择，随机平均梯度下降SAG
    - pennality: 正则优化的种类 **防止过拟合**
    - C: 正则化力度
- 默认将类别数量少的当做正例

- **LogisticRegression**方法相当于**SGDClassifier**(loss='log',penalty='')(Classifier分类器)(线性回归随机梯度是SGDRegressor),SGDClassifier实现一个普通的随机梯度下降学习，也支持平均随机梯度下降法(ASGD),可以通过设置average=True，使用LogisticRegression可以直接实现了SAG，solver='sag'

## 6案例癌症分类预测
- 癌症分类预测-良/恶性乳腺癌肿瘤预测

## 7分类的模型评估
- 我们实际关心的是如果真的患癌症，能够被检查出来的概率

## 8精确率与召回率
- 混淆矩阵
    - 在分类任务下，预测结果(Predicted Codition)与正确标记(True Condition)之间存在四种不同的组合，构成混淆矩阵(适用于多分类)
    - TP True possitive
    - FN False Negative  
    
![混淆矩阵](https://raw.githubusercontent.com/mayu1031/CS_Notes/master/doc/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5.png)

- **精确率Precision**和**召回率Recall**
    - **精确率**: 预测结果为正例样本中真实为正例的比例
        - TP/(TP+FP)
    - **召回率**: 真实为正例的样本中预测结果为正例的比例(查的全，对正样本的区分能力)
        - TP/(TP+FN)
        - 真正患癌症的，能够被检测出来的概率；查的全不全
        - 应用场景: 癌症，工厂质量检测

- F1-score 反映模型的稳健性
    - F1-score高，代表精确率高，召回率也高

![F1-score](https://raw.githubusercontent.com/mayu1031/CS_Notes/master/doc/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/F1-score.png)

### 8.1分类评估API
- **sklearn.metrics.classification_report(y_ture,y_pred,label=[],target_names=None)** (classification_report分类结果报告)
    - y_true:真实目标值
    - y_pred:估计器预测目标值
    - labels:指定类别对应的数字 一般正例为1，负例为0
    - target_names:目标类别名称 比如:[良性，恶性]
    - return:每个目标精确率和召回率
```
print('精确率和召回率为:', classification.report(y_test,lr.predict(x_test)))
```
### 8.2 召回率应用场景
- 工厂里面质量检测，查次品

## 9ROC曲线与AUC指标

总共有100个样本，其中99个样本为癌症，一个样本非癌症  
不管怎么样，我们全部预测正例(默认癌症为正例)- 不负责任  
准确率: 99/100=99%  
召回率: 99/99=100%  
精确率: 99/100=99%  
F1-score: 99.497%  2*99%/(100%+99%)=99.497%  
AUC: 
TPR = 100%  
FPR = 1/1 =100%  
AUC: 1*1/2=0.5

- 造成这样的结果是因为**样本不均衡**，**正样本太多，反例太少**，我们需要找到能够衡量**样本不均衡**情况下分类器的效果引入ROC曲线与AUC指标  


### 9.1知道TPR与FPR
- TPR = TP/(TP+FN) 召回率 
    - 所有真实类别为1的样本中，预测类别为1的比例
- FPR = FP/(FP+TN)
    - 所有真实类别为0的样本中，预测类别为1的比例
- TPR = FPR 不负责任的模型
    - TPR = FPR 斜率为1，AUC为0.5

### 9.2ROC曲线  
![ROC曲线](https://raw.githubusercontent.com/mayu1031/CS_Notes/master/doc/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/ROC%E6%9B%B2%E7%BA%BF.png)  

- ROC曲线的横轴就是FPRate,纵轴就是TPRate，当二者相等时，表示的意义则是:对于不论真实类别是1还是0的样本，分类器预测通通都为1的概率是相等的，此时AUC为0.5，不负责任的模型
- TPR>FPR, 最小值AUC为0.5，最大值极限AUC为1，TPR为1，FPR为0，左上角的点，即所有真实类别为1的样本中，都预测正确为1

### 9.3AUC指标  

- 上图中虚线和x轴y轴包围起来的面积: 
- AUC的概率意义就是随机取一对正负样本，正样本得分大于负样本的概率
- AUC为0.5时，和random guess那条红线重合，是非常不负责任模型
- AUC的最小值为0.5 最大为1 取值越高越好
- **AUC为1，完美分类器，采用这个预测模型是，不管设定什么阈值都能得出完美预测，绝大多数预测的场合，不存在完美分类器**
- **0.5<AUC<1，优于随机猜测，这个分类器(模型)妥善设定阈值的话，能有预测价值**
- 最终AUC的范围在[0.5,1]之间，并且越接近1越好
- 如果出现AUC小于0.5的情况则反着看

### 9.4AUC计算API
- **from sklearn.metrics import roc_auc_score**
- **sklearn.metrics.roc_auc_score(y_true,y_score)**
    - 计算ROC曲线面积，即AUC值
    - y_true: 每个样本的真实类别，必须为0(反例)，1(正例)标记
    - y_score：预测得分，可以是正类的预计概率，置信值或者分类器方法的返回值

### 9.5总结
- AUC只能用来评价二分类
- AUC非常适合评价样本不平衡中的分类性能



