# 逻辑回归与二分类
- 逻辑回归(Logistic Regression)是机器学习中的一种分类模型，逻辑回归是一种分类算法。由于算法的简单和高效，在实际中应用广泛

## 逻辑回归应用场景
- 广告点击率
- 是否为垃圾邮件
- 是否患病
- 金融诈骗
- 虚假账号
- 以上的例子，发现其中的特点，那就是都是属于两个类别之间的判断，逻辑回归就是解决二分类问题的利器

## 逻辑回归的原理
- 输入  
    - h(w)=w1x1+w2x2+w3x3...+b
    - 逻辑回归的输入就是一个线性回归的结果
    - 线性回归的输出，就是逻辑回归的输入
- 激活函数
    - sigmoid函数
    - 将回归结果输入到sigmoid函数当中
    - 输出结果:[0,1]区间中的一个概率值，默认为0.5的阈值 (阈值可以设定，大于阈值，属于这个分类，小于阈值则不属于这个分类)
- 逻辑回归最终的分类是通过属于某个类别的概率值来判断是否属于某个类别，并且这个类别默认标记为1(正例)，另外的一个类别会标记为0(反例)，方便损失计算

![逻辑回归激活函数](https://raw.githubusercontent.com/mayu1031/CS_Notes/master/doc/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0.png)  

![函数图像](https://raw.githubusercontent.com/mayu1031/CS_Notes/master/doc/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/%E5%87%BD%E6%95%B0%E5%9B%BE%E5%83%8F.png)

## 损失函数
- 对数似然损失
    - 分开类别
    - y=1 真实值属于这个类别；当真实值为1，输出结果h(x)越接近1，预测的越准确，则损失函数越低，接近为0
    - y=0 真实值不属于这个类别；当真实值为0，输出结果h(x)越接近0，同理预测结果越准确，则损失函数越低，接近为0

![分开类别](https://raw.githubusercontent.com/mayu1031/CS_Notes/master/doc/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/%E5%AF%B9%E6%95%B0%E4%BC%BC%E7%84%B6%E6%8D%9F%E5%A4%B1.png)  
![当y=1](https://raw.githubusercontent.com/mayu1031/CS_Notes/master/doc/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/%E5%AF%B9%E6%95%B0%E4%BC%BC%E7%84%B6%E6%8D%9F%E5%A4%B1y%3D1.png)  
![当y=0](https://raw.githubusercontent.com/mayu1031/CS_Notes/master/doc/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/%E5%AF%B9%E6%95%B0%E4%BC%BC%E7%84%B6%E6%8D%9F%E5%A4%B1y%3D0.png)  

- 综合完整损失函数

![综合完整损失函数](https://raw.githubusercontent.com/mayu1031/CS_Notes/master/doc/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/%E7%BB%BC%E5%90%88%E5%AE%8C%E6%95%B4%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0.png)  

## 优化损失
- 同样使用梯度下降优化算法，去减少损失函数的值，这样去更新逻辑回归前面对应算法的权重参数，提高原本属于1类别的概率，降低原本是0类别的概率

## 逻辑回归API
- sklearn.linear_model.LogisticRegression(solver='liblinear',penalty='L2',C=1.0)
    - solver: 优化求解方式(默认开源的liblinear库实现，内部使用了坐标轴下降法来迭代优化损失函数)
        - sag:根据数据集自动选择，随机平均梯度下降
    - pennality: 正则优化的种类 防止过拟合
    - C: 正则化力度
- 默认将类别数量少的当做正例
- LogisticRegression方法相当于SGDClassifier(loss='log',penalty='')(Classifier分类器),SGDClassifier实现一个普通的随机梯度下降学习，也支持平均随机梯度下降法(ASGD),可以通过设置average=True。而使用LogisticRegression实现了SAG，solver='sag'

## 案例癌症分类预测
- 癌症分类预测-良/恶性乳腺癌肿瘤预测

# 分类的评估方法
- 真的患癌症，能够被检查出来的概率

## 精确率与召回率
- 混淆矩阵
    - 在分类任务下，预测结果(Predicted Codition)与正确标记(True Condition)之间存在四种不同的组合，构成混淆矩阵(适用于多分类)
    - TP True possitive
    - FN False Negative  
    
![混淆矩阵](https://raw.githubusercontent.com/mayu1031/CS_Notes/master/doc/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5.png)

- 精确率Precision和召唤率Recall
    - 精确率: 预测结果为正例样本中真实为正例的比例
        - TP/(TP+FP)
    - 召回率: 真实为正例的样本中预测结果为正例的比例(查的全，对正样本的区分能力)
        - TP/(TP+FN)
        - 真正患癌症的，能够被检测出来的概率；查的全不全
        - 应用场景: 癌症，工厂质量检测
- F1-score 反映模型的稳健性  

![F1-score](https://raw.githubusercontent.com/mayu1031/CS_Notes/master/doc/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/F1-score.png)

## 分类评估API
- sklearn.metrics,classification_report(y_ture,y_pred,label=[],target_names=None)
    - y_true:真实目标值
    - y_pred:估计器预测目标值
    - labels:指定类别对应的数字
    - target_names:目标类别名称
    - return:每个目标精确率和召回率
```
print('精确率和召回率为:', classification.report(y_test,lr.predict(x_test)))
```
## ROC曲线与AUC指标

总共有100个样本，其中99个样本为癌症，一个样本非癌症  
不管怎么样，我们全部预测正例(默认癌症为正例)- 不负责任  
准确率: 99/100=99%  
召回率: 99/99=100%  
精确率: 99/100=99%  
F1-score: 99.497%  2*99%/(100%+99%)=99.497%  

造成这样的结果是因为样本不均衡，正样本太多，反例太少，我们需要找到能够衡量样本不均衡情况下分类器的效果引入ROC曲线与AUC指标  
AUC:0.5  
     TPR: 100%  
     FPR: 1/1=100%  
     
### 知道TPR与FPR
- TPR = TP/(TP+FN) 召回率 
    - 所有真实类别为1的样本中，预测类别为1的比例
- FPR = FP/(FP+TN)
    - 所有真实类别为0的样本中，预测类别为1的比例
- TPR = FPR 不负责任的模型

### ROC曲线
- ROC曲线的横轴就是FPRate,纵轴就是TPRate，当二者相等时，表示的意义则是:对于不论真实类别是1还是0的样本，分类器预测为1的概率是相等的，此时AUC为0.5
![ROC曲线](https://raw.githubusercontent.com/mayu1031/CS_Notes/master/doc/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/ROC%E6%9B%B2%E7%BA%BF.png)
- TPR>FPR, 最小值AUC为0.5，最大值极限AUC为1，TPR为1，FPR为0，即所有真实类别为1的样本中，都预测正确为1
- AUC的概率意义就是随机取一对正负样本，正样本得分大于负样本的概率
- AUC为0.5时，和random guess那条红线重合，是非常不负责任模型
- AUC的最小值为0.5 最大为1 取值越高越好
- AUC为1，完美分类器，采用这个预测模型是，不管设定什么阈值都能得出完美预测，绝大多数预测的场合，不存在完美分类器
- 0.5<AUC<1，优于随机猜测，这个分类器(模型)妥善设定阈值的话，能有预测价值
- 最终AUC的范围在[0.5,1]之间，并且越接近1越好
- 如果出现AUC小于0.5的情况则反着看

## API
- AUC计算API
- from sklearn.metrics import roc_auc_score
    - sklearn.metrics.roc_auc_score(y_true,y_score)
        - 计算ROC曲线面积，即AUC值
        - y_true: 每个样本的真实类别，必须为0(反例)，1(正例)标记
        - y_score：预测得分，可以是正类的预计概率，置信值或者分类器方法的返回值

## 总结
- AUC只能用来评价二分类
- AUC非常适合评价样本不平衡中的分类性能



