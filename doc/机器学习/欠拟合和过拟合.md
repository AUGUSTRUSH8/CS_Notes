# 欠拟合和过拟合
- 正规方程在现实中用的很少，是因为他不能解决过拟合问题
- 可能会遇见的问题，训练数据训练的很好，误差也不大，但是在测试集上有问题

## 1什么是过拟合和欠拟合
- 过拟合: 一个假设在训练数据上能够获得比其他假设更好的拟合，但是在测试数据集上却不能很好地拟合数据，此时人为这个数据出现了过拟合现象，学习到的特征过多(**模型过于复杂**)
- 欠拟合: 一个假设在训练数据上不能获得更好的拟合，并且在测试数据集上也不能很好的拟合数据，此时认为这个假设出现了欠拟合的现象，学习到的特征过少(**模型过于简单**)  

![过拟合欠拟合](https://raw.githubusercontent.com/mayu1031/CS_Notes/master/doc/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E8%BF%87%E6%8B%9F%E5%90%88%E6%AC%A0%E6%8B%9F%E5%90%88.png)

## 2原因及解决办法
- 欠拟合的原因和解决办法
    - 原因:学习到数据的特征过少
    - 解决办法:增加数据的特征数量
- 过拟合的办法和解决办法
    - 原因:原始特征过多，存在一些嘈杂特征，模型过于复杂是因为模型尝试去兼顾各个测试数据点
    - 解决办法:
        - 使得模型简单些
        - 尽量减少高次项特征的影响
        - 在学习的时候，数据提供的特征有些影响模型复杂度或者这个特征的数据点异常较多，所以算法在学习的时候尽可能减少这个特征的影响(甚至删除某个特征的影响)，这就是特征化
        - 调整时候，算法并不知道某个特征影响，而是去调整参数得出优化的结果
        - **正则化**

- 在这里针对回归，我们选择了正则化，但是对于其他机器学习算法比如分类算法来说也会出现这样的问题，除了一些算法本身作用之外(决策树，神经网络)，我们更多的也是自己去做特征选择，包括之前说的删除，合并一些特征

## 3正则化类别
- L1正则化
    - 作用:可以使得其中一些w的值直接成为0，**删除**这个特征的影响
    - LASSO回归
    - 损失函数+λ惩罚项 惩罚项不是w^2而是**w的绝对值**，造成的结果是可以使得其中一些w的值**直接成为0**

- L2正则化:
    - 作用: 可以使得其中一些w的都很小，都接近0，**削弱某个特征的影响**
    - 优点：越小的参数说明模型越简单，越简单的模型则越不容易产生过拟合现象
    - Ridge回归 岭回归
    - 加入L2正则化后的损失函数: 
        - 损失函数 + λ(惩罚系数) * 惩罚项 
        - 目标: 让损失函数尽可能的小，同时也让惩罚系数尽可能的小，从而让模型提高了准确性还消除了高次项的影响)
    
![正则化类别](https://raw.githubusercontent.com/mayu1031/CS_Notes/master/doc/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E6%AD%A3%E5%88%99%E5%8C%96%E7%B1%BB%E5%88%AB.png)

- L2用的比L1多些

