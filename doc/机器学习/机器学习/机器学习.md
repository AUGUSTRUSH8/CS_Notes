# 什么是机器学习
## 定义
- 机器学习是从数据中自动分析获取模型，并利用模型对未知数据进行预测

## 解释
- 我们人从大量的日常经验中归纳规律，在面临新的问题的时候，可以利用以往总结的规律去分析现实状况，采取最佳策略

## 数据集的构成
- 我们把机器学习要学习的数据称为数据集
- 对于每一行数据我们称之为样本
- 数据集：数据具有特征，目标值为预测结果
- 有些数据集可以没有目标值

## 机器学习算法分类
- 监督学习 supervised learning(预测)
    - 定义：输入数据是由输入特征值和目标值所组成。函数的输出可以是一个连续的值（称为回归），或是输出的是有限的离散值（称为分类），
    - 分类问题 回归 输入数据有特征有标签，即有标准答案
        - 目标值：结果为类别
        - k-近邻算法，朴素贝叶斯分类，决策树，随机森林，逻辑回归
    - 回归问题
        - 目标值:连续型的数据
- 无监督学习 unsupervised learning
    - 定义：输入数据是由输入特征值组成
    - 目标值：没有目标值 输入数据有特征无标签，即无标准答案    
        - 聚类 k-means
        
## 机器学习开发流程
- 获取数据 原始数据
- 数据处理
- 特征工程
- 使用机器学习算法训练 得到模型
- 模型评估

## 学习框架
- 重点  
    - 算法是核心，数据与计算是基础
- 大部分复杂模型的算法设计部都是算法工程师在做，而我们
    - 分析很多数据
    - 分析具体业务
    - 应用常见的算法
    - 特征工程，调参数，优化

# 特征工程
    
## 数据集
### 可用数据集
- kaggle
- UCI数据集
- scikit-learn
### sklearn数据集
- sklearn.datasets
    - load_* 获取小规模数据集
    - fetch_* 获取大规模数据集
        - sklearn.datasets.fetch_name(data_home=None,subset='train')
            - subset：train/test/all

- sklearn数据集返回值介绍
    - load和fetch返回的数据类型都是datasets.base.Bunch 继承自字典
        - data：特征值，特征数据数组，是[n_samples*n_features]的二维
            numpy.ndarray 数组
        - target：目标值，标签数组，是n_samples的一维numpy.ndarray数组
        - DESCR: 数据集描述
        - feature_names: 特征值名字，新闻数据，手写数字，回归数据集没有
        - target_names: 目标值标签名
    - dict['key'] = values 用字典键值对获得数据
      bunch.key = values
      
### 数据集的划分
- 机器学习一般的数据集会划分成两个部分：
    - 训练数据：用于训练，构建模型 70%~80%
    - 测试数据: 在模型检验的时使用，用于评估模型是否有效 20%~30%
- 数据集划分api
    - sklearn.model_selection.trian_test_split(arrays,*options)
    - x 数据集的特征值
        - 训练集特征值 x_train
        - 测试集特征值 x_test
    - y 数据集的标签值
        - 训练集目标值 y_train
        - 测试集目标值 y_test
    - test_size测试集的大小，一般为float
    - random_state随机数种子，不同的种子会造成不同的随机采样结果。相同的种子采样结果相同
    - return 训练集特征值，测试集特征值，训练集目标值，测试集目标值
   
    
### 鸢尾花数据集
- 特征值： 4个特征，花瓣的长度和宽度，花萼的长度，宽度
- 目标值： setosa vericolor virginica
- 数据集划分之后，特征值的数量不变还是四个特征，但是样本的数量变了

## 特征工程介绍
- 什么是特征工程
    - 是是用专业背景知识和技巧处理数据，能得特征能在机器学习算法上发挥更好的作用的过程
    - 目前用的工具 sklearn
- 为什么需要特征工程 Feature Engineering
    - 数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已
- 影响效果的原因
    - 算法
    - 特征工程
- 特征工程的位置与数据处理的比较
    - pandas：一个数据读取非常方便以及基本的处理格式的工具 用于数据清洗，数据处理（缺失值处理）
    - sklearn： 对于特征的处理特供了强大的接口 用于特征工程
- 特征工程包含内容
    - 特征抽取
    - 特征预处理
    - 特征降维

## 特征抽取
- 特征提取
- 机器学习算法 
    - 统计方法, 就是数学公式，但是不能处理字符串，就需要将文本类型的字符串转成成数值类型，即需要特征抽取
        - 文本类型转化成数值
        - 类别，类型转成数值，转换成one-hot编码，哑变量
- 为什么需要特征提取：
    - 将任意数据（如文本或图像）转换成可用于机器学习的数字特征（特征值化）
- 特征提取API
    - sklearn.feature_extraction 是一个类
        - feature 特征
        - extraction 提取
    - 不同类型的数据有不同的转换方法
        - 字典特征提取（特征离散化）
        - 文本特征提取
        - 图像特征提取（深度学习）
     
         
### 字典特征提取  

对字典数据进行特征值化
- sklearn.feature_extraction.DictVectorizer(spars=True...) 默认sparse为True
    - vector 向量 矢量 可以用一维数组来存储向量
        - 矩阵matrix 计算机中用二维数组存储 矩阵可以看成由向量构成
    - Dict Vectorizer 字典vectorizer转换成向量的形式，告诉计算机把字典转出成数值了，可以把每一个样本理解为一个向量，n个样本就是n个向量，可以看成是一个二维数组，也可以理解为矩阵
    - 调用了DictVectorizer，相当于实例化了一个转换器对象，父类是一个transfer，转换器类，其中一个方法就是把字典换成成数值  
    - 调用实例化好的对象DictVectorizer，里面有个方法叫fit_transform
    - DictVectorizer.fit_transform(x) x:字典或者包含字典的迭代器   返回值：返回sparse矩阵 稀疏
        - 稀疏矩阵将非0值按位置表现出来，节省内存，可以提高加载运行效率
    - DictVectorizer.fit_transform(x) x:array数组或者sparse矩阵    返回值：转换之前数据格式
        - DictVectorizer.get_feature_names() 返回类别名称
      
字典特征提取
- 对于特征当中存在类别信息的我们都会做one-hot编码处理，哑变量

应用数据：  
字典：  
```
data = [{'city': '北京', 'temperature': 100}, 
        {'city': '上海', 'temperature': 60}, 
        {'city': '深圳', 'temperature': 30}]
output:      
           [[0,1,0,100]
            [1,0,0,60]
            [0,0,1,30]]
```

每一个样本理解为一个向量，一共三行。三个样本，两个特征，是一个三行两列的二维数组/矩阵
原来每个样本有两个特征，再进行转化之后，字典特征抽取之后，样本量不变，特征数量变成了4个。当特征中有类别的时候，表示方法时字符串，想表示为数值并且数值没有比大小，我们就使用ont-hot变量，哑变量。

#### 字典提取应用场景
- 当我们面对数据集中有类别特征比较多
    - 将数据集的特征转换成字典类型
    - DictVectorizer转换
- 本身拿到的数据类型是字典类型
    
### 文本特征提取
- sklearn.feature_extraction.text.CountVectorizer(stop_words=[])
    - 返回词频矩阵
    - CountVectorizer.fit_transform(x) x:文本或者包含文本字符串的可迭代对象  返回：返回sparse矩阵
    - CountVectorizer.inverse_transform(x) x:array数组或者sparse矩阵 返回值：转换之前数据格
- sklearn.feature_extraction.text.TfidVectorizer
-  一般单词作为特征
 把单词作为特征
 




## 特征预处理


## 特征降维


## 主成分分析


## 总结

# 分类算法

# 回归与聚类算法
