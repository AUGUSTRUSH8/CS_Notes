# 特征预处理
## 1什么是特征预处理
- 通过一些转换函数将**特征数据转换成更加适合算法模型**的特征数据过程
- provides several common utility functions and transformer classes 

### 1.1为什么我们要进行归一化/标准化
- 特征的单位或者大小相差较大，或者某特征的方差相比其他的特征要大出几个数量级，容易影响(支配)目标结果，使得一些算法无法学习到其他的特征

### 1.2数值型数据的无量纲化 
- 因为**量纲**不统一，导致了**某一特征值影响远超其他的特征值**,为了让**特征同等重要**，就需要做数据的**无量纲化**。我们需要用到一些方法进行无量纲化，使不同规格的数据转换到统一规格
    - **归一化**
    - **标准化**

### 1.3特征预处理API
- **sklearn.preprocessing**
- 对于归一化来说，如果出现异常值，影响了最大值和最小值，那么结果会发生改变
- 对于标准化来说，如果出现异常点，由于具有一定数据量，少量的异常点对于平均值的影响并不大，从而对方差标准差的影响较小
```
三个特征：每年获得的飞机常客里程数/里程数，每周消耗的冰淇淋公升数/公升数，玩游戏所有消耗时间的百分比/消耗时间比
评价三个类别： 不喜欢didnt 魅力一般small 极具魅力large
也许说飞机里程数对于结算结果影响较大，但是统计的人觉得这三个特征同等重要
```
## 2归一化
- 通过对原始数据进行变换把数据映射到(默认为[0,1])之间
- 对于归一化来说，如果出现异常值，影响了最大值和最小值，那么结果会发生改变
- 归一化缺陷：如果数据中**异常点**较多，比如**最大值/最小值**，归一化就是用**的最大最小**，所以这种方法鲁棒性较差，只**适合传统精确小数据场景**
- 公式:
![归一化](https://raw.githubusercontent.com/mayu1031/CS_Notes/master/doc/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%89%B9%E5%BE%81%E9%A2%84%E5%A4%84%E7%90%86/%E5%BD%92%E4%B8%80%E5%8C%96.png)

- 作用于每一列，max为一列的最大值，min为每一列的最小值，那么x''为最终结果
- mx，mi分别为指定区间，默认mx为1，mi为0

### 2.1归一化API
- **sklearn.preprocessing.MinMaxScaler(feature_range=(0,1)...)**
    - MinMaxScaler.fit_transform(x)
        - x: numpy array格式的数据[n_samples,n_features]
    - 返回值: 转换后的形状相同的array

```python
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
#获取数据
data = pd.read_csv("dating.txt")
data = data.iloc[:,:3]
#print(data)
#实例化 范围可以自己设定
transfer = MinMaxScaler(feature_range=[2,3])
#调用方法 调用转化器进行转化
data_new = transfer.fit_transform(data)
print(data_new)
```
```
output:
[[ 2.44832535  2.39805139  2.56233353]
 [ 2.15873259  2.34195467  2.98724416]
 [ 2.28542943  2.06892523  2.47449629]
 ..., 
 [ 2.29115949  2.50910294  2.51079493]
 [ 2.52711097  2.43665451  2.4290048 ]
 [ 2.47940793  2.3768091   2.78571804]]
```


## 3标准化
- 通过对原始数据进行变换把数据变换到均值为0，标准差为1范围内
- 对于标准化来说，如果出现异常点，由于具有一定数据量，少量的异常点对于平均值的影响并不大，从而对方差标准差的影响较小
- x'=(x-mean)/σ 
    - mean为平均值，σ为标准差
    - σ：集中程度，离散程度 就算有一些异常数据，σ也不会有大的变化

### 3.1标准化API 
- **sklearn.preprocessing.StandardScaler()**
    - 处理之后，对每列来说，所有数据都聚集在均值为0附近，标准差为1
    - StandardScaler.fit_transform(x)
        - x: numpy array格式的数据[n_samples,n_features]
    - 返回值: 转换后的形状相同的array
- 在已有**样本足够多**的情况下比较稳定，适合现代嘈杂大数据的场景 
```python
from sklearn.preprocessing import StandardScaler
#获取数据
data = pd.read_csv("dating.txt")
data = data.iloc[:,:3]
#print(data)
#实例化 范围可以自己设定
transfer = StandardScaler()
#调用方法 调用转化器进行转化
data_new = transfer.fit_transform(data)
print(data_new)
```
```
output:
[[ 0.33193158  0.41660188  0.24523407]
 [-0.87247784  0.13992897  1.69385734]
 [-0.34554872 -1.20667094 -0.05422437]
 ..., 
 [-0.32171752  0.96431572  0.06952649]
 [ 0.65959911  0.60699509 -0.20931587]
 [ 0.46120328  0.31183342  1.00680598]]
```

