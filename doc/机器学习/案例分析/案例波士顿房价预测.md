# 案例波士顿房价预测
- 数据集介绍,获取数据集
```
实例数量:506
属性数量: 13数值型或类别型，帮助预测的属性；中心位(第14个属性) 经常是学习的目标
属性信息(按顺序)
- CRIM 城镇人均犯罪率 连续值
- ZN 占地面积超过2.5万平方英尺的住宅用地比例 连续值
- INDUS 城镇非零售业务地区的比例 连续值
- CHAS 查尔斯河虚拟变量(=1如果土地在河边；否则为0)，是否邻近查尔斯河 离散值，1=邻近；0=不邻近
- NOX 一氧化氮浓度(每1000万份) 连续值
- RM 每栋房屋的平均客房数 连续值
- AGE 在1940年之前建成的自用单位比例 连续值
- DIS 与五个波士顿就业中心的加权距离 连续值
- RAD 辐射状公路的可达性指数 连续值
- TAX 每10000美元的全额物业税率，全值财产税收 连续值
- PTRATIO 城镇师生比例 连续值
- B 1000(Bk-0.63)^2 其中Bk是城镇的黑人比例 连续值
- LSTAT 低收入人群占比 连续值
- MEDV 同类房屋价格的中位数 连续值

缺失属性值： 无
创建者：Harrison D andRubinfeld D,L
```
- 划分数据集
- 特征工程
    - 无量纲化-标准化
- 预估器流程
    - 可以调整学习率
    - fit()--->模型coef_ intercept_
    
```python
from sklearn.datasets import  load_boston
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression,SGDRegressor,Ridge
from sklearn.metrics import mean_squared_error
def linear_demo1():
    '''
    正规方程的优化方法对波士顿房价进行预测
    :return:
    '''
    # 获取数据
    boston = load_boston()
    # 划分数据集
    x_train,x_test,y_train,y_test = train_test_split(boston.data,boston.target,random_state=22)
    # 特征工程 标准化
    transfer = StandardScaler()
    x_train = transfer.fit_transform(x_train)
    x_test = transfer.fit_transform(x_test)
    # 预估器流程
    estimator = LinearRegression()
    estimator.fit(x_train,y_train)
    # 得出模型
    print("正规方程权重系数为：\n", estimator.coef_)
    print("正规方程偏置为:\n",estimator.intercept_)
    # 模型评估
    y_predict = estimator.predict(x_test)
    print("正规方程预测房价：\n", y_predict)
    error = mean_squared_error(y_test,y_predict)
    print("正规方程均方误差为:\n",error)
    return None


def linear_demo2():
    '''
    梯度下降的优化方法对波士顿房价进行预测
    :return:
    '''
    # 获取数据
    boston = load_boston()
    # 划分数据集
    x_train,x_test,y_train,y_test = train_test_split(boston.data,boston.target,random_state=22)
    # 特征工程 标准化
    transfer = StandardScaler()
    x_train = transfer.fit_transform(x_train)
    x_test = transfer.fit_transform(x_test)
    # 预估器流程, 学习率的算法constant，eta0=0.001 迭代次数10000
    estimator = SGDRegressor(learning_rate="constant",eta0=0.01,max_iter=10000)
    estimator.fit(x_train,y_train)
    # 得出模型
    print("梯度下降权重系数为：\n", estimator.coef_)
    print("梯度下降偏置为:\n",estimator.intercept_)
    # 模型评估
    y_predict = estimator.predict(x_test)
    print("梯度下降预测房价：\n", y_predict)
    error = mean_squared_error(y_test, y_predict)
    print("梯度下降均方误差为:\n", error)
    return None
    

def linear_demo3():
    '''
    岭回归对波士顿房价进行预测
    :return:
    '''
    # 获取数据
    boston = load_boston()
    # 划分数据集
    x_train,x_test,y_train,y_test = train_test_split(boston.data,boston.target,random_state=22)
    # 特征工程 标准化
    transfer = StandardScaler()
    x_train = transfer.fit_transform(x_train)
    x_test = transfer.fit_transform(x_test)
    # 预估器流程, 学习率的算法constant，eta0=0.001 迭代次数10000
    estimator = Ridge(alpha=0.5,max_iter=10000)
    estimator.fit(x_train,y_train)
    # 得出模型
    print("岭回归权重系数为：\n", estimator.coef_)
    print("岭回归偏置为:\n",estimator.intercept_)
    # 模型评估
    y_predict = estimator.predict(x_test)
    print("岭回归预测房价：\n", y_predict)
    error = mean_squared_error(y_test, y_predict)
    print("岭回归均方误差为:\n", error)
    return None
    
    
if __name__ == "__main__":
    linear_demo1()
    linear_demo2()
    linear_demo3()
    
    
output:
正规方程权重系数为：
 [-0.63330277  1.14524456 -0.05645213  0.74282329 -1.95823403  2.70614818
 -0.07544614 -3.29771933  2.49437742 -1.85578218 -1.7518438   0.8816005
 -3.92011059]
正规方程偏置为:
 22.6213720317
正规方程预测房价：
 [ 28.15624208  31.30869316  20.51485702  31.48205292  19.01722351
  18.25171434  20.57503703  18.45503556  18.46192151  32.94820922
  20.36213103  27.24752425  14.81963448  19.21146435  37.02505033
  18.32408346   7.70119888  17.56478207  30.19561854  23.61297215
  18.13379616  33.84017096  28.49921616  16.99629682  34.76148752
  26.227388    34.84170356  26.6267998   18.63962161  13.21549955
  30.36603792  14.70412444  37.18508975   8.91445391  15.06484067
  16.12468763   7.21797311  19.16335583  39.57444328  28.24501235
  24.62961494  16.72956407  37.82734499   5.70546434  21.20919004
  24.63811904  18.85963528  19.93919917  15.20065511  26.3036171
   7.4251188   27.14868579  29.19076714  16.28206033   7.94953105
  35.46279456  32.39096932  20.83555382  16.41378444  20.87373635
  22.92853043  23.61293997  19.32937197  38.34148716  23.87879591
  18.96954218  12.59209375   6.13512682  41.45864696  21.09486655
  16.23896752  21.48997696  40.7412586   20.4923302   36.81939833
  27.05431089  19.80309379  19.61594823  24.59557969  21.0926586
  30.92608611  19.33654808  22.30425056  31.09257529  26.36682634
  20.25040256  28.82330164  20.82975275  26.02088244  19.38265499
  24.96346722  22.30487912  18.92534649  18.86319188  14.02247729
  17.42627701  24.19757886  15.83147538  20.07623475  26.5274431
  20.1203599   17.01175154  23.87970119  22.84994222  21.01501787
  36.18004225  14.68047932  20.5703347   32.46950515  33.24267189
  19.81863526  26.56674006  20.90143053  16.41628584  20.76797132
  20.55412335  26.86514583  24.14833578  23.24521672  13.80658275
  15.37015731   2.78305654  28.90480222  19.78978857  21.50300566
  27.54836226  28.55537501]
正规方程均方误差为:
 20.0616866377
梯度下降权重系数为：
 [-1.1367301   1.29981158  0.01371703  0.70522691 -1.87924507  3.02783621
 -0.13158741 -3.35524493  2.51781459 -1.98037893 -2.10577075  0.74408847
 -4.14145192]
梯度下降偏置为:
 [ 22.98278092]
梯度下降预测房价：
 [ 28.79591589  32.46529121  20.6972206   32.27031095  19.02129416
  17.95845514  20.69062811  18.46059213  18.56479906  34.66701464
  20.58748893  27.41442739  14.47701213  19.29277326  39.1825514
  18.24197237   7.99499827  17.3565987   31.39513908  24.10611464
  17.94206754  35.88374581  29.30872993  16.11266615  36.13360925
  26.84557962  36.50572459  27.8286162   17.93750467  13.21106655
  32.18228073  14.72516264  39.61450296   6.1218561   14.69429992
  15.67196206   4.75423195  18.81753535  41.53287574  29.19937696
  25.09020445  16.64918092  39.21170216   4.03874703  20.99464407
  25.20875726  19.57341391  20.07851485  14.61924293  26.06095451
   6.83551472  27.94966016  29.86064671  15.09612234   7.58621584
  37.58702537  33.67752148  21.42633293  16.47071909  21.29911939
  23.28304646  23.8337421   19.28305196  40.44993115  24.65416451
  18.70292604  12.56611894   3.97841096  43.70120616  21.35786865
  16.15306576  21.87778958  43.4805356   20.76593801  39.11440314
  27.69318539  20.34802499  20.21777059  25.34028844  21.97115867
  32.01543659  19.56686171  22.4464336   33.0804518   27.12579609
  20.00946688  29.68493871  21.17930608  26.39383785  19.69575129
  26.03327167  22.35866282  18.904526    15.39559851  14.20725576
  17.27986265  24.66620958  15.75625322  19.83976949  27.05527824
  19.79054531  16.61507865  24.76015783  23.19264809  21.42980927
  37.45522173  14.32648618  21.014171    34.06632711  33.50908983
  20.01364528  27.32089996  22.03374396  16.37183233  20.89150303
  21.60194373  28.33491462  25.38779336  23.63872617  12.92319984
  14.45680619   0.80002118  29.81417126  19.77184892  21.75293765
  28.27667111  29.81715417]
梯度下降均方误差为:
 19.9206057374
岭回归权重系数为：
 [-0.62710135  1.13221555 -0.07373898  0.74492864 -1.93983515  2.71141843
 -0.07982198 -3.27753496  2.44876703 -1.81107644 -1.74796456  0.88083243
 -3.91211699]
岭回归偏置为:
 22.6213720317
岭回归预测房价：
 [ 28.14980988  31.30005476  20.52972351  31.47072569  19.03738471
  18.2515444   20.58448636  18.46065814  18.47822278  32.9253545
  20.37688914  27.22040283  14.82433783  19.21909702  37.01094366
  18.31298687   7.73702695  17.57853316  30.19905513  23.61558173
  18.1326241   33.8248652   28.47676462  16.98519213  34.74283555
  26.21305152  34.80802748  26.62860932  18.63287977  13.28180355
  30.35485268  14.64609607  37.18577474   8.94068221  15.08489513
  16.10551255   7.22956076  19.15050136  39.5565419   28.26158947
  24.6308918   16.73535852  37.83410495   5.70268785  21.19002891
  24.62163908  18.88282355  19.94727347  15.19726616  26.29340687
   7.48806536  27.12758369  29.18672591  16.28031052   7.96550163
  35.44152785  32.33687405  20.89719296  16.42392256  20.87865837
  22.93165628  23.59993258  19.34765346  38.31082831  23.93493948
  18.96042932  12.60794029   6.13152953  41.45558456  21.09635345
  16.21825908  21.50546787  40.73024272  20.51662557  36.80209391
  27.04140791  19.86329311  19.62868177  24.59984417  21.18141704
  30.93357762  19.33695661  22.30651013  31.08556136  26.38132198
  20.24561514  28.80939986  20.8464224   26.0336187   19.31848012
  24.94485661  22.29733644  18.92673912  18.89328211  14.03554422
  17.42114021  24.18168589  15.83222588  20.05992382  26.52337056
  20.11082706  17.01706162  23.86414957  22.83910743  20.95125604
  36.14672616  14.70106802  20.62471484  32.45392546  33.20953724
  19.819153    26.51317386  20.93727618  16.44072777  20.76683347
  20.57365666  26.86331703  24.16771227  23.236999    13.79408517
  15.37608273   2.77999575  28.89574935  19.7879507   21.50537858
  27.54615553  28.52655513]
岭回归均方误差为:
 20.0626506883
```
